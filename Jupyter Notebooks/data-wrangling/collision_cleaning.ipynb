{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your methodology for loading the data\n",
    "df = pd.read_csv('data/Motor_Vehicle_Collisions_-_Crashes_20231202.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Null Values\\n{df.isnull().sum()}')\n",
    "print(\"---------------------------------------\")\n",
    "print(f'Number of Duplicated Values: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting CRASH DATE and CRASH TIME to datetime\n",
    "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
    "df['CRASH TIME'] = pd.to_datetime(df['CRASH TIME'])\n",
    "\n",
    "#Add description of each col and the reason for deleting the columns\n",
    "useful_cols=['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE',\n",
    "       'LONGITUDE', 'LOCATION','ON STREET NAME','CROSS STREET NAME', 'NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1',\n",
    "       'CONTRIBUTING FACTOR VEHICLE 2','COLLISION_ID', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2']\n",
    "df_c_1=df[useful_cols]\n",
    "\n",
    "\n",
    "drop_null_cols=['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE',\n",
    "       'LONGITUDE','CONTRIBUTING FACTOR VEHICLE 1','NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED','VEHICLE TYPE CODE 1']\n",
    "df_c_2=df_c_1.dropna(subset=drop_null_cols).reset_index(drop=True)\n",
    "print(\"Rows with non-null values in important columns:\",df_c_2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_reason_df = pd.read_excel('data/contributing_factor.xlsx')\n",
    "\n",
    "reason_dict = {}\n",
    "for i in acc_reason_df.index:\n",
    "  if acc_reason_df['broader_category'][i] in reason_dict:\n",
    "    reason_dict[acc_reason_df['broader_category'][i]].append(acc_reason_df['contributing_factor'][i])\n",
    "  else:\n",
    "    reason_dict[acc_reason_df['broader_category'][i]] = [acc_reason_df['contributing_factor'][i]]\n",
    "\n",
    "## Adding a new columns with a broader category of weather conditions\n",
    "def get_categories(x):\n",
    "  for k in reason_dict.keys():\n",
    "    if x in reason_dict[k]:\n",
    "      return k\n",
    "\n",
    "df_c_2['broader_contributing_factors'] = df_c_2['CONTRIBUTING FACTOR VEHICLE 1'].apply(get_categories)\n",
    "df_c_2=df_c_2.dropna(subset=['broader_contributing_factors']).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_c_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fws-datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
